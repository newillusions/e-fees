name: Performance Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: true
        default: 'smoke'
        type: choice
        options:
          - smoke
          - load
          - stress
          - endurance
          - full
      data_scale:
        description: 'Test data scale'
        required: true
        default: 'small'
        type: choice
        options:
          - small
          - medium
          - large

env:
  NODE_VERSION: '18'
  PERFORMANCE_THRESHOLD_SCORE: 75
  SURREALDB_TEST_URL: ws://localhost:8000
  SURREALDB_TEST_NS: emittiv_ci
  SURREALDB_TEST_DB: projects_ci
  SURREALDB_TEST_USER: ci_user
  SURREALDB_TEST_PASS: ci_password

jobs:
  performance-testing:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    services:
      surrealdb:
        image: surrealdb/surrealdb:latest
        ports:
          - 8000:8000
        options: >-
          --health-cmd "curl -f http://localhost:8000/health || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        env:
          SURREAL_USER: ci_user
          SURREAL_PASS: ci_password
    
    strategy:
      matrix:
        test-suite: 
          - ${{ github.event.inputs.test_suite == '' && 'smoke' || github.event.inputs.test_suite }}
      fail-fast: false
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Needed for performance trend analysis
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install k6
      run: |
        sudo gpg -k
        sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
    
    - name: Install SurrealDB CLI
      run: |
        curl --proto '=https' --tlsv1.2 -sSf https://install.surrealdb.com | sh
        sudo mv ~/.local/share/surrealdb/surreal /usr/local/bin/
    
    - name: Install project dependencies
      run: |
        npm ci
        npm run perf:install
    
    - name: Setup test database
      run: |
        # Wait for SurrealDB to be ready
        timeout 30 bash -c 'until curl -f http://localhost:8000/health; do sleep 1; done'
        
        # Initialize test database
        surreal sql --conn http://localhost:8000 --user ci_user --pass ci_password --ns emittiv_ci --db projects_ci --file performance/data/fixtures/test-schema.surql || echo "Schema setup skipped"
    
    - name: Generate test data
      run: |
        export TEST_ENV=ci
        export SURREALDB_TEST_URL=ws://localhost:8000
        npm run perf:generate-data -- ${{ github.event.inputs.data_scale || 'small' }}
    
    - name: Create performance baseline (if needed)
      run: |
        if [ ! -f "performance/reports/trends/baseline.json" ]; then
          echo "Creating initial performance baseline..."
          npm run perf:baseline
        fi
    
    - name: Run performance tests
      id: performance_tests
      run: |
        export TEST_ENV=ci
        export TEST_SUITE=${{ matrix.test-suite }}
        
        case "$TEST_SUITE" in
          smoke)
            npm run perf:test:smoke
            ;;
          load)
            npm run perf:test:database
            npm run perf:test:workflows
            ;;
          stress)
            npm run perf:test:database
            npm run perf:test:workflows
            npm run perf:test:memory
            ;;
          endurance)
            timeout 45m npm run perf:test:memory
            timeout 30m npm run perf:test:workflows
            ;;
          full)
            npm run perf:test
            ;;
          *)
            echo "Unknown test suite: $TEST_SUITE"
            exit 1
            ;;
        esac
      
      continue-on-error: true  # Allow report generation even if tests fail
    
    - name: Run regression analysis
      id: regression_analysis
      run: |
        npm run perf:compare
        
        # Check if regression analysis passed
        if [ -f "performance/reports/trends/regression-results.json" ]; then
          REGRESSION_COUNT=$(jq '.summary.regressions | length' performance/reports/trends/regression-results.json)
          CRITICAL_REGRESSIONS=$(jq '.summary.critical_regressions | length' performance/reports/trends/regression-results.json)
          
          echo "regressions=$REGRESSION_COUNT" >> $GITHUB_OUTPUT
          echo "critical_regressions=$CRITICAL_REGRESSIONS" >> $GITHUB_OUTPUT
          
          if [ "$CRITICAL_REGRESSIONS" -gt 0 ]; then
            echo "‚ùå Critical performance regressions detected!"
            echo "critical_regression_detected=true" >> $GITHUB_OUTPUT
          else
            echo "critical_regression_detected=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "‚ö†Ô∏è Regression analysis results not found"
          echo "critical_regression_detected=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Generate performance report
      run: |
        npm run perf:report
        
        # Extract overall performance score
        if [ -f "performance/reports/json/performance-summary.json" ]; then
          PERFORMANCE_SCORE=$(jq '.overall.score // 0' performance/reports/json/performance-summary.json)
          echo "Performance Score: $PERFORMANCE_SCORE"
          echo "PERFORMANCE_SCORE=$PERFORMANCE_SCORE" >> $GITHUB_ENV
        fi
    
    - name: Upload performance test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-test-results-${{ matrix.test-suite }}-${{ github.run_number }}
        path: |
          performance/reports/
          performance/logs/
        retention-days: 30
    
    - name: Upload performance HTML report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-html-report-${{ matrix.test-suite }}-${{ github.run_number }}
        path: performance/reports/html/
        retention-days: 30
    
    - name: Comment PR with performance results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          let comment = '## üöÄ Performance Test Results\n\n';
          
          // Add test suite info
          comment += `**Test Suite:** ${{ matrix.test-suite }}\n`;
          comment += `**Data Scale:** ${{ github.event.inputs.data_scale || 'small' }}\n`;
          comment += `**Commit:** ${context.sha.substring(0, 7)}\n\n`;
          
          // Add performance score
          const score = process.env.PERFORMANCE_SCORE || 'N/A';
          if (score !== 'N/A') {
            const scoreEmoji = score >= 90 ? 'üü¢' : score >= 75 ? 'üü°' : 'üî¥';
            comment += `**Overall Performance Score:** ${scoreEmoji} ${score}/100\n\n`;
          }
          
          // Add regression info
          const regressions = '${{ steps.regression_analysis.outputs.regressions }}';
          const criticalRegressions = '${{ steps.regression_analysis.outputs.critical_regressions }}';
          
          if (regressions !== '') {
            comment += `**Regressions Detected:** ${regressions}\n`;
            comment += `**Critical Regressions:** ${criticalRegressions}\n\n`;
          }
          
          // Add test status
          const testSuccess = '${{ steps.performance_tests.outcome }}' === 'success';
          const testEmoji = testSuccess ? '‚úÖ' : '‚ùå';
          comment += `**Test Status:** ${testEmoji} ${testSuccess ? 'Passed' : 'Failed'}\n\n`;
          
          // Add recommendations
          if (score < 75 || criticalRegressions > 0) {
            comment += '### ‚ö†Ô∏è Action Required\n\n';
            if (score < 75) {
              comment += '- Performance score below threshold (75). Review performance optimizations.\n';
            }
            if (criticalRegressions > 0) {
              comment += '- Critical performance regressions detected. Address before merging.\n';
            }
            comment += '\n';
          }
          
          comment += '### üìä Detailed Reports\n\n';
          comment += `- Check the "Actions" tab for detailed performance reports\n`;
          comment += `- Download artifacts: \`performance-html-report-${{ matrix.test-suite }}-${{ github.run_number }}\`\n`;
          
          // Post comment
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
    
    - name: Fail job on critical regressions
      if: steps.regression_analysis.outputs.critical_regression_detected == 'true'
      run: |
        echo "‚ùå Critical performance regressions detected!"
        echo "This build will fail to prevent deployment of performance issues."
        exit 1
    
    - name: Fail job on low performance score
      if: env.PERFORMANCE_SCORE != '' && env.PERFORMANCE_SCORE < env.PERFORMANCE_THRESHOLD_SCORE
      run: |
        echo "‚ùå Performance score ($PERFORMANCE_SCORE) below threshold ($PERFORMANCE_THRESHOLD_SCORE)!"
        echo "Please review and optimize performance before merging."
        exit 1
    
    - name: Cleanup test data
      if: always()
      run: |
        npm run perf:clean || echo "Cleanup completed"

  performance-trend-analysis:
    runs-on: ubuntu-latest
    needs: performance-testing
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: |
        npm ci
        cd performance && npm install
    
    - name: Download performance results
      uses: actions/download-artifact@v4
      with:
        pattern: performance-test-results-*
        merge-multiple: true
        path: performance/reports/
    
    - name: Update performance trends
      run: |
        cd performance
        node utils/monitoring/update-trends.js
    
    - name: Commit updated trends
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        if [ -n "$(git status --porcelain)" ]; then
          git add performance/reports/trends/
          git commit -m "chore: update performance trends [skip ci]"
          git push
        else
          echo "No changes to commit"
        fi

  performance-report-deployment:
    runs-on: ubuntu-latest
    needs: performance-testing
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download performance HTML reports
      uses: actions/download-artifact@v4
      with:
        pattern: performance-html-report-*
        merge-multiple: true
        path: performance-reports/
    
    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: performance-reports/
        destination_dir: performance-reports/
        keep_files: true
    
    - name: Comment with report URL
      if: github.event_name == 'push'
      uses: actions/github-script@v7
      with:
        script: |
          const reportUrl = `https://${context.repo.owner}.github.io/${context.repo.repo}/performance-reports/`;
          
          const comment = `üöÄ **Performance Report Deployed**
          
          üìä Latest performance report is now available at: ${reportUrl}
          
          This report includes detailed analysis of:
          - Database performance metrics
          - UI rendering performance
          - Memory usage patterns
          - Workflow execution times
          - Historical trend analysis
          `;
          
          // Create a commit comment
          github.rest.repos.createCommitComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            commit_sha: context.sha,
            body: comment
          });

  notify-on-failure:
    runs-on: ubuntu-latest
    needs: [performance-testing, performance-trend-analysis]
    if: failure() && github.ref == 'refs/heads/main'
    
    steps:
    - name: Notify team of performance test failure
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        text: |
          üö® Performance tests failed on main branch!
          
          Repository: ${{ github.repository }}
          Commit: ${{ github.sha }}
          Actor: ${{ github.actor }}
          
          Please review the performance test results and address any critical issues.
        webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
      if: env.SLACK_WEBHOOK_URL != ''